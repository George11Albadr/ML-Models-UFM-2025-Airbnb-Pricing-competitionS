{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13a60e85-1554-47e9-b258-e1cbd4443e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 6. Hyperparameter Tuning con GridSearchCV en Notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    BaggingRegressor\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44652ea7-42bd-4c24-abad-4c314e2a4e9f",
   "metadata": {},
   "source": [
    "# Carga de de datos preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13ee0825-668d-484d-9e19-724ff6888112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo cwd: C:\\Users\\George\\Documents\\GitHub\\ML-Models-UFM-2025-Airbnb-Pricing-competition\\airbnb-price-determinant\n"
     ]
    }
   ],
   "source": [
    "# %% 0. Asegurar cwd en la ra√≠z del proyecto\n",
    "import os\n",
    "\n",
    "# opci√≥n 1: con magia de Jupyter\n",
    "# %cd C:/Users/George/Documents/GitHub/ML-Models-UFM-2025-Airbnb-Pricing-competition/airbnb-price-determinant\n",
    "\n",
    "# opci√≥n 2: con os.chdir\n",
    "os.chdir(r\"C:\\Users\\George\\Documents\\GitHub\\ML-Models-UFM-2025-Airbnb-Pricing-competition\\airbnb-price-determinant\")\n",
    "\n",
    "print(\"Nuevo cwd:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9aeff67-ecad-4ee2-93d7-68fb9078b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carga preprocesados\n",
    "df = pd.read_csv(\"data/02_intermediate/train_processed.csv\")\n",
    "X = df.drop([\"id\", \"realSum\"], axis=1)\n",
    "y = df[\"realSum\"].astype(float)\n",
    "\n",
    "# 2. Split interno (otra vez) para HPO\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aeeaec-1f15-46e0-abd2-dfbaf11183d8",
   "metadata": {},
   "source": [
    " # Definimos Grids de b√∫squeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8b74628-ab76-47dc-98bd-f41a6ceeff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 3. Define grids de b√∫squeda\n",
    "from sklearn.tree import DecisionTreeRegressor  # ya lo tienes importado\n",
    "\n",
    "param_grids = {\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestRegressor(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [None, 10, 20]\n",
    "        }\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"model\": GradientBoostingRegressor(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.05, 0.1]\n",
    "        }\n",
    "    },\n",
    "    \"AdaBoost\": {\n",
    "        \"model\": AdaBoostRegressor(\n",
    "            estimator=DecisionTreeRegressor(max_depth=3),  # <- usa \"estimator\"\n",
    "            random_state=42\n",
    "        ),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100],\n",
    "            \"learning_rate\": [0.5, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \"Bagging\": {\n",
    "        \"model\": BaggingRegressor(\n",
    "            estimator=DecisionTreeRegressor(max_depth=5),  # <- usa \"estimator\"\n",
    "            random_state=42\n",
    "        ),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [10, 50],\n",
    "            \"max_samples\": [0.8, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"model\": KNeighborsRegressor(),\n",
    "        \"params\": {\n",
    "            \"n_neighbors\": [5, 10, 20]\n",
    "        }\n",
    "    },\n",
    "    \"SGD\": {\n",
    "        \"model\": SGDRegressor(random_state=42),\n",
    "        \"params\": {\n",
    "            \"alpha\": [1e-4, 1e-3, 1e-2],\n",
    "            \"max_iter\": [1000, 2000]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbfc94f5-b40b-4b4c-8319-7987da7deceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Shapes:\n",
      "   X_train_proc: (28956, 25)\n",
      "   X_valid_proc: (7239, 25)\n",
      "   y_train     : (28956,)\n",
      "   y_valid     : (7239,)\n"
     ]
    }
   ],
   "source": [
    "# %% Carga datasets preprocesados\n",
    "import pandas as pd\n",
    "\n",
    "# 1Ô∏è‚É£ Lee los CSVs que guardaste al final del EDA\n",
    "train_df = pd.read_csv(\"data/02_intermediate/train_processed.csv\")\n",
    "valid_df = pd.read_csv(\"data/02_intermediate/valid_processed.csv\")\n",
    "\n",
    "# 2Ô∏è‚É£ Separa caracter√≠sticas y target\n",
    "X_train_proc = train_df.drop([\"id\", \"realSum\"], axis=1)\n",
    "y_train      = train_df[\"realSum\"].astype(float)\n",
    "X_valid_proc = valid_df.drop([\"id\", \"realSum\"], axis=1)\n",
    "y_valid      = valid_df[\"realSum\"].astype(float)\n",
    "\n",
    "# 3Ô∏è‚É£ Comprueba que todo carg√≥ correctamente\n",
    "print(\"‚ñ∂Ô∏è Shapes:\")\n",
    "print(\"   X_train_proc:\", X_train_proc.shape)\n",
    "print(\"   X_valid_proc:\", X_valid_proc.shape)\n",
    "print(\"   y_train     :\", y_train.shape)\n",
    "print(\"   y_valid     :\", y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e1101-8a24-4356-b486-1c19d92316a8",
   "metadata": {},
   "source": [
    "# Verificaci√≥n de Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b61beb2-6d94-4872-926d-7de443efd1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs en X_train_proc: 0\n",
      "NaNs en X_valid_proc: 0\n",
      "NaNs en y_train     : 0\n",
      "NaNs en y_valid     : 0\n",
      "‚úÖ Despu√©s de todo, no quedan NaNs:\n",
      "   X_train_proc: (28956, 25), y_train: (28956,)\n",
      "   X_valid_proc: (7238, 25), y_valid: (7238,)\n"
     ]
    }
   ],
   "source": [
    "# %% 5.x+ Sanity‚Äêcheck final e imputaci√≥n de target\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1Ô∏è‚É£ Imputar s√≥lo caracter√≠sticas con la media de X_train\n",
    "train_means = X_train_proc.mean()\n",
    "X_train_proc = X_train_proc.fillna(train_means)\n",
    "X_valid_proc = X_valid_proc.fillna(train_means)\n",
    "\n",
    "# 2Ô∏è‚É£ Filtrar filas donde target o features tengan NaNs\n",
    "mask_train = (~X_train_proc.isna().any(axis=1)) & (~y_train.isna())\n",
    "mask_valid = (~X_valid_proc.isna().any(axis=1)) & (~y_valid.isna())\n",
    "\n",
    "X_train_proc = X_train_proc.loc[mask_train]\n",
    "y_train      = y_train.loc[mask_train]\n",
    "X_valid_proc = X_valid_proc.loc[mask_valid]\n",
    "y_valid      = y_valid.loc[mask_valid]\n",
    "\n",
    "# 3Ô∏è‚É£ Asegur√©monos de que ya no queden NaNs\n",
    "assert X_train_proc.isna().sum().sum() == 0\n",
    "assert X_valid_proc.isna().sum().sum() == 0\n",
    "assert y_train.isna().sum() == 0\n",
    "assert y_valid.isna().sum() == 0\n",
    "\n",
    "# 5.x.1) Comprueba cu√°ntos NaNs hay en features y target\n",
    "print(\"NaNs en X_train_proc:\", X_train_proc.isna().sum().sum())\n",
    "print(\"NaNs en X_valid_proc:\", X_valid_proc.isna().sum().sum())\n",
    "print(\"NaNs en y_train     :\", y_train.isna().sum())\n",
    "print(\"NaNs en y_valid     :\", y_valid.isna().sum())\n",
    "\n",
    "print(\"‚úÖ Despu√©s de todo, no quedan NaNs:\")\n",
    "print(f\"   X_train_proc: {X_train_proc.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"   X_valid_proc: {X_valid_proc.shape}, y_valid: {y_valid.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa299e8-fdc3-45e5-9340-bb516dbdf594",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc03dd9b-adca-4c6a-9654-4fd3d11fb79e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Random Forest ‚Äî tuning hiperpar√°metros‚Ä¶\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "‚è±Ô∏è Elapsed: 1 min\n",
      "‚è±Ô∏è Elapsed: 2 min\n",
      "‚è±Ô∏è Elapsed: 3 min\n",
      "\n",
      "‚úÖ GridSearchCV completado en 3.00 min\n",
      "‚úî Random Forest ‚Äî Best params: {'max_depth': None, 'n_estimators': 100}\n",
      "    MAE:  62.89 | RMSE: 185.66 | R¬≤: 0.5778\n"
     ]
    }
   ],
   "source": [
    "# %% 6.1 Hyperparameter Tuning Random Forest con cron√≥metro y append a resultados\n",
    "\n",
    "import time\n",
    "import threading\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# 0Ô∏è‚É£ Inicializa la lista de resultados (solo la primera vez)\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    results = []\n",
    "\n",
    "# 1Ô∏è‚É£ Aseg√∫rate de tener en memoria:\n",
    "#    X_train_proc, y_train, X_valid_proc, y_valid\n",
    "\n",
    "# 2Ô∏è‚É£ Define tu modelo y grid\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\":    [None, 10, 20]\n",
    "}\n",
    "\n",
    "gs_rf = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1  # para ver progreso de cada fold\n",
    ")\n",
    "\n",
    "# 3Ô∏è‚É£ Cron√≥metro en un hilo aparte (imprime cada 60‚ÄØs)\n",
    "stop_timer = False\n",
    "def _print_timer():\n",
    "    mins = 0\n",
    "    while not stop_timer:\n",
    "        time.sleep(60)\n",
    "        mins += 1\n",
    "        print(f\"‚è±Ô∏è Elapsed: {mins} min\")\n",
    "\n",
    "timer_thread = threading.Thread(target=_print_timer, daemon=True)\n",
    "timer_thread.start()\n",
    "\n",
    "# 4Ô∏è‚É£ Fit + medici√≥n total\n",
    "start_time = time.time()\n",
    "print(\"üîé Random Forest ‚Äî tuning hiperpar√°metros‚Ä¶\")\n",
    "gs_rf.fit(X_train_proc, y_train)\n",
    "\n",
    "# parar cron√≥metro\n",
    "stop_timer = True\n",
    "timer_thread.join()\n",
    "\n",
    "total_min = (time.time() - start_time) / 60\n",
    "print(f\"\\n‚úÖ GridSearchCV completado en {total_min:.2f} min\")\n",
    "\n",
    "# 5Ô∏è‚É£ Evaluaci√≥n sobre validaci√≥n\n",
    "best_rf = gs_rf.best_estimator_\n",
    "preds_rf = best_rf.predict(X_valid_proc)\n",
    "\n",
    "mse_rf  = mean_squared_error(y_valid, preds_rf)\n",
    "rmse_rf = mse_rf ** 0.5\n",
    "mae_rf  = mean_absolute_error(y_valid, preds_rf)\n",
    "r2_rf   = r2_score(y_valid, preds_rf)\n",
    "\n",
    "print(f\"‚úî Random Forest ‚Äî Best params: {gs_rf.best_params_}\")\n",
    "print(f\"    MAE:  {mae_rf:,.2f} | RMSE: {rmse_rf:,.2f} | R¬≤: {r2_rf:.4f}\")\n",
    "\n",
    "# 6Ô∏è‚É£ Append a la lista de resultados\n",
    "results.append({\n",
    "    \"model\":       \"RandomForest\",\n",
    "    \"best_params\": gs_rf.best_params_,\n",
    "    \"mae\":         mae_rf,\n",
    "    \"rmse\":        rmse_rf,\n",
    "    \"r2\":          r2_rf\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c366e8-9621-40b2-a6d9-afc8405779b2",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07bb909b-fd1e-4b90-9def-fb5a0368d947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Gradient Boosting ‚Äî tuning hiperpar√°metros‚Ä¶\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "‚è±Ô∏è Elapsed: 1 min\n",
      "\n",
      "‚úÖ GridSearchCV completado en 1.00 min\n",
      "‚úî Gradient Boosting ‚Äî Best params: {'model__learning_rate': 0.05, 'model__n_estimators': 200}\n",
      "    MAE:  82.10 | RMSE: 236.67 | R¬≤: 0.3139\n"
     ]
    }
   ],
   "source": [
    "# %% 6.2 Hyperparameter Tuning Gradient Boosting (Opci√≥n A) con cron√≥metro y append\n",
    "\n",
    "import time\n",
    "import threading\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# 0Ô∏è‚É£ Inicializa la lista de resultados si a√∫n no existe\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    results = []\n",
    "\n",
    "# 1Ô∏è‚É£ Aseg√∫rate de tener en memoria:\n",
    "#    X_train_proc, y_train, X_valid_proc, y_valid\n",
    "\n",
    "# 2Ô∏è‚É£ Pipeline y grid de b√∫squeda\n",
    "pipe_gb = Pipeline([\n",
    "    (\"model\", GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "gb_param_grid = {\n",
    "    \"model__n_estimators\":    [100, 200],\n",
    "    \"model__learning_rate\":   [0.05, 0.1]\n",
    "}\n",
    "\n",
    "gs_gb = GridSearchCV(\n",
    "    estimator=pipe_gb,\n",
    "    param_grid=gb_param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 3Ô∏è‚É£ Cron√≥metro en hilo aparte (imprime cada 60‚ÄØs)\n",
    "stop_timer_gb = False\n",
    "def _print_timer_gb():\n",
    "    mins = 0\n",
    "    while not stop_timer_gb:\n",
    "        time.sleep(60)\n",
    "        mins += 1\n",
    "        print(f\"‚è±Ô∏è Elapsed: {mins} min\")\n",
    "\n",
    "timer_thread_gb = threading.Thread(target=_print_timer_gb, daemon=True)\n",
    "timer_thread_gb.start()\n",
    "\n",
    "# 4Ô∏è‚É£ Fit + medici√≥n total\n",
    "start_time = time.time()\n",
    "print(\"üîé Gradient Boosting ‚Äî tuning hiperpar√°metros‚Ä¶\")\n",
    "gs_gb.fit(X_train_proc, y_train)\n",
    "stop_timer_gb = True\n",
    "timer_thread_gb.join()\n",
    "\n",
    "total_min = (time.time() - start_time) / 60\n",
    "print(f\"\\n‚úÖ GridSearchCV completado en {total_min:.2f} min\")\n",
    "\n",
    "# 5Ô∏è‚É£ Evaluaci√≥n sobre validaci√≥n\n",
    "best_gb   = gs_gb.best_estimator_\n",
    "preds_gb  = best_gb.predict(X_valid_proc)\n",
    "\n",
    "mse_gb    = mean_squared_error(y_valid, preds_gb)\n",
    "rmse_gb   = np.sqrt(mse_gb)\n",
    "mae_gb    = mean_absolute_error(y_valid, preds_gb)\n",
    "r2_gb     = r2_score(y_valid, preds_gb)\n",
    "\n",
    "print(f\"‚úî Gradient Boosting ‚Äî Best params: {gs_gb.best_params_}\")\n",
    "print(f\"    MAE:  {mae_gb:,.2f} | RMSE: {rmse_gb:,.2f} | R¬≤: {r2_gb:.4f}\")\n",
    "\n",
    "# 6Ô∏è‚É£ Append a la lista de resultados\n",
    "results.append({\n",
    "    \"model\":       \"GradientBoosting\",\n",
    "    \"best_params\": gs_gb.best_params_,\n",
    "    \"mae\":         mae_gb,\n",
    "    \"rmse\":        rmse_gb,\n",
    "    \"r2\":          r2_gb\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8940f270-c73c-40aa-a4ff-df088e08b200",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc62eb5e-6292-43ea-8123-35553484be2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé AdaBoost ‚Äî tuning hiperpar√°metros sobre X_train_proc‚Ä¶\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "‚úÖ GridSearchCV AdaBoost completado en 0.06 min\n",
      "‚úî AdaBoost ‚Äî Mejores par√°metros: {'learning_rate': 0.5, 'n_estimators': 50}\n",
      "    MAE:  135.34 | RMSE: 267.04 | R¬≤: 0.1265\n"
     ]
    }
   ],
   "source": [
    "# %% 6.3 Hyperparameter Tuning AdaBoost (Opci√≥n A) con cron√≥metro y append\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# 0Ô∏è‚É£ Aseg√∫rate de que la lista `results` exista\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    results = []\n",
    "\n",
    "# 1Ô∏è‚É£ Define el grid para AdaBoost directamente sobre X_train_proc\n",
    "ab_param_grid = {\n",
    "    \"n_estimators\":  [50, 100],\n",
    "    \"learning_rate\": [0.5, 1.0]\n",
    "}\n",
    "\n",
    "# 2Ô∏è‚É£ Prepara y lanza el GridSearchCV\n",
    "print(\"üîé AdaBoost ‚Äî tuning hiperpar√°metros sobre X_train_proc‚Ä¶\")\n",
    "t0 = time.time()\n",
    "gs_ab = GridSearchCV(\n",
    "    estimator=AdaBoostRegressor(\n",
    "        estimator=DecisionTreeRegressor(max_depth=3),\n",
    "        random_state=42\n",
    "    ),\n",
    "    param_grid=ab_param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    error_score=\"raise\"\n",
    ")\n",
    "gs_ab.fit(X_train_proc, y_train)\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "print(f\"\\n‚úÖ GridSearchCV AdaBoost completado en {elapsed_min:.2f} min\")\n",
    "\n",
    "# 3Ô∏è‚É£ Evaluaci√≥n en validaci√≥n\n",
    "best_ab  = gs_ab.best_estimator_\n",
    "preds_ab = best_ab.predict(X_valid_proc)\n",
    "\n",
    "mse_ab   = mean_squared_error(y_valid, preds_ab)\n",
    "rmse_ab  = np.sqrt(mse_ab)\n",
    "mae_ab   = mean_absolute_error(y_valid, preds_ab)\n",
    "r2_ab    = r2_score(y_valid, preds_ab)\n",
    "\n",
    "print(f\"‚úî AdaBoost ‚Äî Mejores par√°metros: {gs_ab.best_params_}\")\n",
    "print(f\"    MAE:  {mae_ab:,.2f} | RMSE: {rmse_ab:,.2f} | R¬≤: {r2_ab:.4f}\")\n",
    "\n",
    "# 4Ô∏è‚É£ Append a la lista de resultados\n",
    "results.append({\n",
    "    \"model\":       \"AdaBoost\",\n",
    "    \"best_params\": gs_ab.best_params_,\n",
    "    \"mae\":         mae_ab,\n",
    "    \"rmse\":        rmse_ab,\n",
    "    \"r2\":          r2_ab\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c09129-f8f4-4631-930e-c76ddffd1474",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "899d9d30-a9ad-42d4-bb17-60769340e1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Bagging ‚Äî tuning hiperpar√°metros sobre X_train_proc‚Ä¶\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "‚úÖ GridSearchCV Bagging completado en 0.22 min\n",
      "‚úî Bagging ‚Äî Mejores par√°metros: {'max_samples': 1.0, 'n_estimators': 50}\n",
      "    MAE:  90.91 | RMSE: 230.34 | R¬≤: 0.3501\n"
     ]
    }
   ],
   "source": [
    "# %% 6.4 Hyperparameter Tuning BaggingRegressor (Opci√≥n A) con cron√≥metro y append\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# 0Ô∏è‚É£ Aseg√∫rate de que la lista `results` exista\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    results = []\n",
    "\n",
    "# 1Ô∏è‚É£ Define el grid para Bagging directamente sobre X_train_proc\n",
    "bg_param_grid = {\n",
    "    \"n_estimators\": [10, 50],\n",
    "    \"max_samples\":  [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# 2Ô∏è‚É£ Prepara y lanza el GridSearchCV\n",
    "print(\"üîé Bagging ‚Äî tuning hiperpar√°metros sobre X_train_proc‚Ä¶\")\n",
    "t0 = time.time()\n",
    "gs_bg = GridSearchCV(\n",
    "    estimator=BaggingRegressor(\n",
    "        estimator=DecisionTreeRegressor(max_depth=5),\n",
    "        random_state=42\n",
    "    ),\n",
    "    param_grid=bg_param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    error_score=\"raise\"\n",
    ")\n",
    "gs_bg.fit(X_train_proc, y_train)\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "print(f\"\\n‚úÖ GridSearchCV Bagging completado en {elapsed_min:.2f} min\")\n",
    "\n",
    "# 3Ô∏è‚É£ Evaluaci√≥n en validaci√≥n\n",
    "best_bg  = gs_bg.best_estimator_\n",
    "preds_bg = best_bg.predict(X_valid_proc)\n",
    "\n",
    "mse_bg   = mean_squared_error(y_valid, preds_bg)\n",
    "rmse_bg  = np.sqrt(mse_bg)\n",
    "mae_bg   = mean_absolute_error(y_valid, preds_bg)\n",
    "r2_bg    = r2_score(y_valid, preds_bg)\n",
    "\n",
    "print(f\"‚úî Bagging ‚Äî Mejores par√°metros: {gs_bg.best_params_}\")\n",
    "print(f\"    MAE:  {mae_bg:,.2f} | RMSE: {rmse_bg:,.2f} | R¬≤: {r2_bg:.4f}\")\n",
    "\n",
    "# 4Ô∏è‚É£ Append a la lista de resultados\n",
    "results.append({\n",
    "    \"model\":       \"Bagging\",\n",
    "    \"best_params\": gs_bg.best_params_,\n",
    "    \"mae\":         mae_bg,\n",
    "    \"rmse\":        rmse_bg,\n",
    "    \"r2\":          r2_bg\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2c9335-bfac-44cf-8f55-97e80cf26439",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16f3590b-9374-426c-ba90-b93f9db39080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé KNN ‚Äî tuning hiperpar√°metros sobre X_train_proc‚Ä¶\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "\n",
      "‚úÖ GridSearchCV KNN completado en 0.04 min\n",
      "‚úî KNN ‚Äî Mejores par√°metros: {'n_neighbors': 20}\n",
      "    MAE:  83.67 | RMSE: 234.20 | R¬≤: 0.3282\n"
     ]
    }
   ],
   "source": [
    "# %% K-Nearest Neighbors tuning sobre datos preprocesados + timing\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# 0Ô∏è‚É£ Aseg√∫rate de que la lista `results` exista\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    results = []\n",
    "\n",
    "# 1Ô∏è‚É£ Definimos el par√°metro grid para KNN\n",
    "knn_param_grid = {\n",
    "    \"n_neighbors\": [5, 10, 20]\n",
    "}\n",
    "\n",
    "# 2Ô∏è‚É£ Creamos y ejecutamos el GridSearchCV directamente sobre X_train_proc\n",
    "print(\"üîé KNN ‚Äî tuning hiperpar√°metros sobre X_train_proc‚Ä¶\")\n",
    "t0 = time.time()\n",
    "gs_knn = GridSearchCV(\n",
    "    estimator=KNeighborsRegressor(),\n",
    "    param_grid=knn_param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    error_score=\"raise\"\n",
    ")\n",
    "gs_knn.fit(X_train_proc, y_train)\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "print(f\"\\n‚úÖ GridSearchCV KNN completado en {elapsed_min:.2f} min\")\n",
    "\n",
    "# 3Ô∏è‚É£ Evaluaci√≥n en validaci√≥n\n",
    "best_knn  = gs_knn.best_estimator_\n",
    "preds_knn = best_knn.predict(X_valid_proc)\n",
    "\n",
    "mse_knn   = mean_squared_error(y_valid, preds_knn)\n",
    "rmse_knn  = np.sqrt(mse_knn)\n",
    "mae_knn   = mean_absolute_error(y_valid, preds_knn)\n",
    "r2_knn    = r2_score(y_valid, preds_knn)\n",
    "\n",
    "print(f\"‚úî KNN ‚Äî Mejores par√°metros: {gs_knn.best_params_}\")\n",
    "print(f\"    MAE:  {mae_knn:,.2f} | RMSE: {rmse_knn:,.2f} | R¬≤: {r2_knn:.4f}\")\n",
    "\n",
    "# 4Ô∏è‚É£ Append a la lista de resultados\n",
    "results.append({\n",
    "    \"model\":       \"KNN\",\n",
    "    \"best_params\": gs_knn.best_params_,\n",
    "    \"mae\":         mae_knn,\n",
    "    \"rmse\":        rmse_knn,\n",
    "    \"r2\":          r2_knn\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48604e43-51eb-4cc0-91e9-202c6f0ff608",
   "metadata": {},
   "source": [
    "# SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d59a2a16-85eb-486a-9d3f-72a0987fd92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé SGDRegressor ‚Äî tuning hiperpar√°metros sobre X_train_proc‚Ä¶\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "\n",
      "‚úÖ GridSearchCV SGDRegressor completado en 0.02¬†min\n",
      "‚úî SGDRegressor ‚Äî Mejores par√°metros: {'alpha': 0.0001, 'max_iter': 1000}\n",
      "    MAE:  101.24 | RMSE: 244.21 | R¬≤: 0.2695\n"
     ]
    }
   ],
   "source": [
    "# %% SGDRegressor tuning sobre datos preprocesados + timing\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# 0Ô∏è‚É£ Aseg√∫rate de que la lista `results` exista\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    results = []\n",
    "\n",
    "# 1Ô∏è‚É£ Define el grid para SGDRegressor\n",
    "sgd_param_grid = {\n",
    "    \"alpha\":    [1e-4, 1e-3, 1e-2],\n",
    "    \"max_iter\": [1000, 2000]\n",
    "}\n",
    "\n",
    "# 2Ô∏è‚É£ Lanza la b√∫squeda de hiperpar√°metros directamente sobre X_train_proc\n",
    "print(\"üîé SGDRegressor ‚Äî tuning hiperpar√°metros sobre X_train_proc‚Ä¶\")\n",
    "t0 = time.time()\n",
    "gs_sgd = GridSearchCV(\n",
    "    estimator=SGDRegressor(random_state=42),\n",
    "    param_grid=sgd_param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    error_score=\"raise\",\n",
    ")\n",
    "gs_sgd.fit(X_train_proc, y_train)\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "print(f\"\\n‚úÖ GridSearchCV SGDRegressor completado en {elapsed_min:.2f}¬†min\")\n",
    "\n",
    "# 3Ô∏è‚É£ Eval√∫a en validaci√≥n\n",
    "best_sgd  = gs_sgd.best_estimator_\n",
    "preds_sgd = best_sgd.predict(X_valid_proc)\n",
    "\n",
    "mse_sgd   = mean_squared_error(y_valid, preds_sgd)\n",
    "rmse_sgd  = np.sqrt(mse_sgd)\n",
    "mae_sgd   = mean_absolute_error(y_valid, preds_sgd)\n",
    "r2_sgd    = r2_score(y_valid, preds_sgd)\n",
    "\n",
    "print(f\"‚úî SGDRegressor ‚Äî Mejores par√°metros: {gs_sgd.best_params_}\")\n",
    "print(f\"    MAE:  {mae_sgd:,.2f} | RMSE: {rmse_sgd:,.2f} | R¬≤: {r2_sgd:.4f}\")\n",
    "\n",
    "# 4Ô∏è‚É£ Append a la lista de resultados\n",
    "results.append({\n",
    "    \"model\":       \"SGDRegressor\",\n",
    "    \"best_params\": gs_sgd.best_params_,\n",
    "    \"mae\":         mae_sgd,\n",
    "    \"rmse\":        rmse_sgd,\n",
    "    \"r2\":          r2_sgd\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cebe31-c14a-4a0e-b0b7-e7321229c762",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebb6a346-f3ee-49ed-ab67-4277c1b10342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Stacking (meta) ‚Äî tuning hiperpar√°metros‚Ä¶\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "‚úÖ GridSearchCV Stacking completado en 70.58 min\n",
      "‚úî Stacking ‚Äî Best meta‚Äëparams: {'stack__final_estimator__learning_rate': 0.05, 'stack__final_estimator__max_depth': 3, 'stack__final_estimator__n_estimators': 100}\n",
      "    MAE:  65.73 | RMSE: 201.95 | R¬≤: 0.5005\n"
     ]
    }
   ],
   "source": [
    "# %% 7. Stacking (meta) ‚Äî tuning hiperpar√°metros sobre datos preprocesados + timing\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import StackingRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# 0Ô∏è‚É£ Aseg√∫rate de que `results` exista\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    results = []\n",
    "\n",
    "# 1Ô∏è‚É£ Define el pipeline con el StackingRegressor                                             \n",
    "pipe_stack = Pipeline([\n",
    "    (\n",
    "        \"stack\",\n",
    "        StackingRegressor(\n",
    "            estimators=[\n",
    "                (\"rf\",  best_rf),\n",
    "                (\"gb\",  best_gb),\n",
    "                (\"ab\",  best_ab),\n",
    "                (\"bg\",  best_bg),\n",
    "                (\"knn\", best_knn),\n",
    "                (\"sgd\", best_sgd),\n",
    "            ],\n",
    "            final_estimator=GradientBoostingRegressor(random_state=42),\n",
    "            n_jobs=-1,\n",
    "            passthrough=False,\n",
    "        ),\n",
    "    )\n",
    "])\n",
    "\n",
    "# 2Ô∏è‚É£ Grid de hiperpar√°metros para el meta‚Äëestimador\n",
    "param_grid_stack = {\n",
    "    \"stack__final_estimator__n_estimators\":  [50, 100, 200],\n",
    "    \"stack__final_estimator__learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"stack__final_estimator__max_depth\":     [3, 5, 7],\n",
    "}\n",
    "\n",
    "# 3Ô∏è‚É£ Lanza el GridSearchCV\n",
    "print(\"üîé Stacking (meta) ‚Äî tuning hiperpar√°metros‚Ä¶\")\n",
    "t0 = time.time()\n",
    "gs_stack = GridSearchCV(\n",
    "    estimator=pipe_stack,\n",
    "    param_grid=param_grid_stack,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    error_score=\"raise\"\n",
    ")\n",
    "gs_stack.fit(X_train_proc, y_train)\n",
    "elapsed_min = (time.time() - t0) / 60\n",
    "print(f\"‚úÖ GridSearchCV Stacking completado en {elapsed_min:.2f} min\")\n",
    "\n",
    "# 4Ô∏è‚É£ Evaluaci√≥n sobre validaci√≥n\n",
    "best_stack = gs_stack.best_estimator_\n",
    "preds_st   = best_stack.predict(X_valid_proc)\n",
    "\n",
    "mse_st  = mean_squared_error(y_valid, preds_st)    # MSE\n",
    "rmse_st = np.sqrt(mse_st)                          # RMSE manual\n",
    "mae_st  = mean_absolute_error(y_valid, preds_st)\n",
    "r2_st   = r2_score(y_valid, preds_st)\n",
    "\n",
    "print(f\"‚úî Stacking ‚Äî Best meta‚Äëparams: {gs_stack.best_params_}\")\n",
    "print(f\"    MAE:  {mae_st:,.2f} | RMSE: {rmse_st:,.2f} | R¬≤: {r2_st:.4f}\")\n",
    "\n",
    "# 5Ô∏è‚É£ Append a la lista de resultados\n",
    "results.append({\n",
    "    \"model\":       \"Stacking\",\n",
    "    \"best_params\": gs_stack.best_params_,\n",
    "    \"mae\":         mae_st,\n",
    "    \"rmse\":        rmse_st,\n",
    "    \"r2\":          r2_st\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c7d06f5-a77c-4703-b6ca-35641032683a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>62.885952</td>\n",
       "      <td>185.658486</td>\n",
       "      <td>0.577802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>62.885952</td>\n",
       "      <td>185.658486</td>\n",
       "      <td>0.577802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>62.885952</td>\n",
       "      <td>185.658486</td>\n",
       "      <td>0.577802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>62.885952</td>\n",
       "      <td>185.658486</td>\n",
       "      <td>0.577802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>62.885952</td>\n",
       "      <td>185.658486</td>\n",
       "      <td>0.577802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>62.885952</td>\n",
       "      <td>185.658486</td>\n",
       "      <td>0.577802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>62.885952</td>\n",
       "      <td>185.658486</td>\n",
       "      <td>0.577802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>{'stack__final_estimator__learning_rate': 0.05...</td>\n",
       "      <td>65.727598</td>\n",
       "      <td>201.945329</td>\n",
       "      <td>0.500478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>{'max_samples': 1.0, 'n_estimators': 50}</td>\n",
       "      <td>90.906420</td>\n",
       "      <td>230.339274</td>\n",
       "      <td>0.350136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 20}</td>\n",
       "      <td>83.672270</td>\n",
       "      <td>234.198086</td>\n",
       "      <td>0.328179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__n_estim...</td>\n",
       "      <td>82.096808</td>\n",
       "      <td>236.673506</td>\n",
       "      <td>0.313902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>{'alpha': 0.0001, 'max_iter': 1000}</td>\n",
       "      <td>101.242917</td>\n",
       "      <td>244.212296</td>\n",
       "      <td>0.269497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 50}</td>\n",
       "      <td>135.335671</td>\n",
       "      <td>267.040341</td>\n",
       "      <td>0.126545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "               model                                        best_params  \\\n",
       "\u001b[1;36m0\u001b[0m       RandomForest           \u001b[1m{\u001b[0m\u001b[32m'max_depth'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m100\u001b[0m\u001b[1m}\u001b[0m   \n",
       "\u001b[1;36m1\u001b[0m   GradientBoosting           \u001b[1m{\u001b[0m\u001b[32m'max_depth'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m100\u001b[0m\u001b[1m}\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m           AdaBoost           \u001b[1m{\u001b[0m\u001b[32m'max_depth'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m100\u001b[0m\u001b[1m}\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m            Bagging           \u001b[1m{\u001b[0m\u001b[32m'max_depth'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m100\u001b[0m\u001b[1m}\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m                KNN           \u001b[1m{\u001b[0m\u001b[32m'max_depth'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m100\u001b[0m\u001b[1m}\u001b[0m   \n",
       "\u001b[1;36m5\u001b[0m       SGDRegressor           \u001b[1m{\u001b[0m\u001b[32m'max_depth'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m100\u001b[0m\u001b[1m}\u001b[0m   \n",
       "\u001b[1;36m6\u001b[0m       RandomForest           \u001b[1m{\u001b[0m\u001b[32m'max_depth'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m100\u001b[0m\u001b[1m}\u001b[0m   \n",
       "\u001b[1;36m7\u001b[0m           Stacking  \u001b[1m{\u001b[0m\u001b[32m'stack__final_estimator__learning_rate'\u001b[0m: \u001b[1;36m0.05\u001b[0m\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m8\u001b[0m            Bagging           \u001b[1m{\u001b[0m\u001b[32m'max_samples'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m50\u001b[0m\u001b[1m}\u001b[0m   \n",
       "\u001b[1;36m9\u001b[0m                KNN                                \u001b[1m{\u001b[0m\u001b[32m'n_neighbors'\u001b[0m: \u001b[1;36m20\u001b[0m\u001b[1m}\u001b[0m   \n",
       "\u001b[1;36m10\u001b[0m  GradientBoosting  \u001b[1m{\u001b[0m\u001b[32m'model__learning_rate'\u001b[0m: \u001b[1;36m0.05\u001b[0m, 'model__n_estim\u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m11\u001b[0m      SGDRegressor                \u001b[1m{\u001b[0m\u001b[32m'alpha'\u001b[0m: \u001b[1;36m0.0001\u001b[0m, \u001b[32m'max_iter'\u001b[0m: \u001b[1;36m1000\u001b[0m\u001b[1m}\u001b[0m   \n",
       "\u001b[1;36m12\u001b[0m          AdaBoost         \u001b[1m{\u001b[0m\u001b[32m'learning_rate'\u001b[0m: \u001b[1;36m0.5\u001b[0m, \u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m50\u001b[0m\u001b[1m}\u001b[0m   \n",
       "\n",
       "           mae        rmse        r2  \n",
       "\u001b[1;36m0\u001b[0m    \u001b[1;36m62.885952\u001b[0m  \u001b[1;36m185.658486\u001b[0m  \u001b[1;36m0.577802\u001b[0m  \n",
       "\u001b[1;36m1\u001b[0m    \u001b[1;36m62.885952\u001b[0m  \u001b[1;36m185.658486\u001b[0m  \u001b[1;36m0.577802\u001b[0m  \n",
       "\u001b[1;36m2\u001b[0m    \u001b[1;36m62.885952\u001b[0m  \u001b[1;36m185.658486\u001b[0m  \u001b[1;36m0.577802\u001b[0m  \n",
       "\u001b[1;36m3\u001b[0m    \u001b[1;36m62.885952\u001b[0m  \u001b[1;36m185.658486\u001b[0m  \u001b[1;36m0.577802\u001b[0m  \n",
       "\u001b[1;36m4\u001b[0m    \u001b[1;36m62.885952\u001b[0m  \u001b[1;36m185.658486\u001b[0m  \u001b[1;36m0.577802\u001b[0m  \n",
       "\u001b[1;36m5\u001b[0m    \u001b[1;36m62.885952\u001b[0m  \u001b[1;36m185.658486\u001b[0m  \u001b[1;36m0.577802\u001b[0m  \n",
       "\u001b[1;36m6\u001b[0m    \u001b[1;36m62.885952\u001b[0m  \u001b[1;36m185.658486\u001b[0m  \u001b[1;36m0.577802\u001b[0m  \n",
       "\u001b[1;36m7\u001b[0m    \u001b[1;36m65.727598\u001b[0m  \u001b[1;36m201.945329\u001b[0m  \u001b[1;36m0.500478\u001b[0m  \n",
       "\u001b[1;36m8\u001b[0m    \u001b[1;36m90.906420\u001b[0m  \u001b[1;36m230.339274\u001b[0m  \u001b[1;36m0.350136\u001b[0m  \n",
       "\u001b[1;36m9\u001b[0m    \u001b[1;36m83.672270\u001b[0m  \u001b[1;36m234.198086\u001b[0m  \u001b[1;36m0.328179\u001b[0m  \n",
       "\u001b[1;36m10\u001b[0m   \u001b[1;36m82.096808\u001b[0m  \u001b[1;36m236.673506\u001b[0m  \u001b[1;36m0.313902\u001b[0m  \n",
       "\u001b[1;36m11\u001b[0m  \u001b[1;36m101.242917\u001b[0m  \u001b[1;36m244.212296\u001b[0m  \u001b[1;36m0.269497\u001b[0m  \n",
       "\u001b[1;36m12\u001b[0m  \u001b[1;36m135.335671\u001b[0m  \u001b[1;36m267.040341\u001b[0m  \u001b[1;36m0.126545\u001b[0m  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_results = pd.DataFrame(results).sort_values(\"rmse\").reset_index(drop=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d76049-0677-4bec-8abc-6005b7c35c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (airbnb_price_determinant)",
   "language": "python",
   "name": "kedro_airbnb_price_determinant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
